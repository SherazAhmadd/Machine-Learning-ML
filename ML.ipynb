{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Theory of Machine Learning\n",
    "## What is Machine Learning\n",
    "> Machine Learning is type of AI or we can call the working behind AI is based on Machine learning which allows to predict more accurate outcomes\n",
    "  \n",
    "***\n",
    "### Types of Machine Learning\n",
    "1. **supervised Machine learning**\n",
    "2. **un-supervised Machine Learning**\n",
    "3. **semi-supervised Machine Learning**\n",
    "4. **Reinforcement**\n",
    "   \n",
    "***\n",
    "### 1. **Supervised Machine Learning**\n",
    "   *Divided into two main types*\n",
    "   - **Regression**\n",
    "     - Linear Regression (one line regression)\n",
    "     - MultiLinear Regression (Multi line regression --> two or more variables)\n",
    "     - Polynomial Regression (All other shape regressions)\n",
    "     - Logistic Regression (S-shape function/regression --> both continous and discrete Variables)\n",
    "     - Random forest\n",
    "   - **Classification**\n",
    "      - Decision_Tree (true false conditions)\n",
    "      - K-nearest neighbors (nearest points on K number)\n",
    "### 2. **Un-Supervised Machine Learning**\n",
    "  - *Clustering*\n",
    "  - *Association mining rule*\n",
    "  - *Dimensionality Reduction*\n",
    "\n",
    "### 3. **Semi-supervised Machine Learning**\n",
    "### 4. ***Reinforcement**\n",
    "***\n",
    "\n",
    "# Models working strategy's\n",
    "### 1. Decision Tree\n",
    "- working on if-else statment\n",
    "- yes or no situation\n",
    "- top condition is Root node\n",
    "- and then classifying into child nodes until it comes to leaf node\n",
    "- sensitive on training data\n",
    "- simplest and Fast\n",
    "- Condition in node is Also known as Optimal splitting point\n",
    "- Information Gain(IG) is calculated by an equation which have entropy and gini index\n",
    "- Splitting based on theory called **Entropy** \n",
    "- **Entropy** is termed as how much information stored in single condition(measure of Information) ---> **entropy** = E - pi log(pi)\n",
    "- **Gini** measure of randomness or impurity in condition  ---> **gini** = 1-e (pi)^2   // e is simission\n",
    "- parent nodes does'nt care about child node or next split\n",
    "- ovefitting is problem for this model\n",
    "  \n",
    "***\n",
    "### 2. Random forest \n",
    " - Random forest is formed by forming multiple Decision tree's model\n",
    " - less sensitive on training data\n",
    " - random means normalize random Values gained from decision tree's\n",
    " - forest is multiple Tree's\n",
    " - in this model Data is divided into sub-set data and then it goes to multiple Decision tree's and then get the mean of all values to get the final prediction\n",
    " - sub-set is splitting the random data from Main training Data\n",
    " - creating sub-set from data is known as **Bootstapping**\n",
    " - Aggrigation is sum of all values from DTS and then get the mean \n",
    " - In regression --> mean whereas classification --> mode\n",
    " - **Bootstapping + Aggregation = Bagging**\n",
    " - highly accurate\n",
    " - overfitting is not problem\n",
    " - hard to intrepet\n",
    "\n",
    "### 3. Polynomial Regresion \n",
    " - in this model,Linear regression line but with curve\n",
    "  \n",
    "### 4. Naive bayes\n",
    " - naive bayes is classifier model\n",
    " - it worked on 1/2 probability\n",
    " - does'nt require big data for training\n",
    "\n",
    "### 5. Support vector machine\n",
    " - In SVM, we divide the data into classes using separator or HyperPlane \n",
    " - And the technique we using for creating classes is kernaling\n",
    " - separator is bard of blockage between data\n",
    " - Kernaling is Transforming data from 1D to 2D so that it will easy to use separator among them\n",
    " - types of kernaling\n",
    "   - Linear \n",
    "   - polynomial\n",
    "   - RBF(radio basis function)\n",
    "   - sigmoid \n",
    " -  Basically don't need to remember these types, Python is much intelligent and knows which type of kernel to use \n",
    " -  cons\n",
    "    -  SVM do not provide Probability estimators\n",
    "    -  overfitting but incase if no.of features is more than no of sample\n",
    "    -  not good for big dataset more than 1000 rows\n",
    " - Used-in:\n",
    "   - Image recognization\n",
    "   - text mining \n",
    "   - Gene expression and data classification(bioinformatics)\n",
    "   - Regression outlies detection and clustering  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
